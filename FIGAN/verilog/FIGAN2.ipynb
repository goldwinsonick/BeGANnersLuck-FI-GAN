{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ecb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "import os\n",
    "\n",
    "# --- KONFIGURASI ---\n",
    "DATA_WIDTH = 16\n",
    "SCALE = 2 ** 10\n",
    "np.random.seed(123) # Seed konsisten\n",
    "\n",
    "BASE_DIR = \"data/generator_test\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "# File Paths\n",
    "FILE_IN      = os.path.join(BASE_DIR, \"gen_input.csv\")\n",
    "FILE_WEIGHTS = os.path.join(BASE_DIR, \"gen_weights.txt\")\n",
    "FILE_REF_L0  = os.path.join(BASE_DIR, \"ref_layer0.csv\")\n",
    "FILE_REF_L1  = os.path.join(BASE_DIR, \"ref_layer1.csv\")\n",
    "\n",
    "def to_q6_10(x):\n",
    "    val = int(round(x * SCALE))\n",
    "    return max(min(val, 32767), -32768)\n",
    "\n",
    "# Hardware-Accurate LeakyReLU (13/64 approx 0.203125)\n",
    "def leaky_relu_hw(x):\n",
    "    return np.where(x > 0, x, x * (13/64))\n",
    "\n",
    "def run_trans_layer(img, w, b):\n",
    "    # 1. Upsample (Insert Zero)\n",
    "    h, w_img = img.shape\n",
    "    up = np.zeros((h*2, w_img*2))\n",
    "    for r in range(h):\n",
    "        for c in range(w_img):\n",
    "            up[r*2, c*2] = img[r, c]\n",
    "    # 2. Conv Valid\n",
    "    res = scipy.signal.correlate2d(up, w, mode='valid') + b\n",
    "    return res\n",
    "\n",
    "print(\"Generating Slow Debug Data...\")\n",
    "\n",
    "# 1. Input 8x8\n",
    "input_img = np.random.uniform(-1, 1, (8, 8))\n",
    "\n",
    "# 2. Weights\n",
    "w0 = np.random.uniform(-0.5, 0.5, (4, 4)); b0 = 0.1\n",
    "w1 = np.random.uniform(-0.5, 0.5, (4, 4)); b1 = -0.05\n",
    "w_dummy = np.zeros((3,3)); b_dummy = 0\n",
    "\n",
    "# 3. Calculate Reference\n",
    "# Layer 0 (8x8 -> 13x13)\n",
    "l0_conv = run_trans_layer(input_img, w0, b0)\n",
    "l0_act  = leaky_relu_hw(l0_conv)\n",
    "\n",
    "# Layer 1 (13x13 -> 23x23)\n",
    "l1_conv = run_trans_layer(l0_act, w1, b1)\n",
    "l1_act  = leaky_relu_hw(l1_conv)\n",
    "\n",
    "print(f\"Ref L0 Shape: {l0_act.shape}\")\n",
    "print(f\"Ref L1 Shape: {l1_act.shape}\")\n",
    "\n",
    "# 4. Save Files\n",
    "np.savetxt(FILE_IN, np.vectorize(to_q6_10)(input_img).flatten(), fmt='%d')\n",
    "np.savetxt(FILE_REF_L0, np.vectorize(to_q6_10)(l0_act).flatten(), fmt='%d')\n",
    "np.savetxt(FILE_REF_L1, np.vectorize(to_q6_10)(l1_act).flatten(), fmt='%d')\n",
    "\n",
    "# Save Weights\n",
    "weights_list = []\n",
    "weights_list.extend(w0.flatten()); weights_list.append(b0)\n",
    "weights_list.extend(w1.flatten()); weights_list.append(b1)\n",
    "weights_list.extend(w_dummy.flatten()); weights_list.append(b_dummy)\n",
    "\n",
    "with open(FILE_WEIGHTS, 'w') as f:\n",
    "    for val in weights_list:\n",
    "        f.write(f\"{to_q6_10(val) & 0xFFFF:04x}\\n\")\n",
    "\n",
    "print(\"Files Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704f14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "SCALE = 2 ** 10\n",
    "BASE_DIR = \"data/generator_test\"\n",
    "\n",
    "# Paths\n",
    "REF_L0 = os.path.join(BASE_DIR, \"ref_layer0.csv\")\n",
    "RTL_L0 = os.path.join(BASE_DIR, \"rtl_layer0.csv\")\n",
    "REF_L1 = os.path.join(BASE_DIR, \"ref_layer1.csv\")\n",
    "RTL_L1 = os.path.join(BASE_DIR, \"rtl_layer1.csv\")\n",
    "\n",
    "def load_data(path, shape):\n",
    "    try:\n",
    "        data = np.loadtxt(path, dtype=int)\n",
    "        expected = shape[0] * shape[1]\n",
    "        if data.size != expected:\n",
    "            # Pad or Crop biar script gak crash, tapi print warning\n",
    "            if data.size < expected:\n",
    "                data = np.pad(data, (0, expected - data.size))\n",
    "            else:\n",
    "                data = data[:expected]\n",
    "        return data.reshape(shape) / SCALE\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {path}: {e}\")\n",
    "        return np.zeros(shape)\n",
    "\n",
    "print(\"Verifying Slow Mode...\")\n",
    "\n",
    "# Layer 0\n",
    "ref0 = load_data(REF_L0, (13, 13))\n",
    "rtl0 = load_data(RTL_L0, (13, 13))\n",
    "err0 = np.max(np.abs(ref0 - rtl0))\n",
    "print(f\"Layer 0 Max Error: {err0:.6f}\")\n",
    "\n",
    "# Layer 1\n",
    "ref1 = load_data(REF_L1, (23, 23))\n",
    "rtl1 = load_data(RTL_L1, (23, 23))\n",
    "err1 = np.max(np.abs(ref1 - rtl1))\n",
    "print(f\"Layer 1 Max Error: {err1:.6f}\")\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# L0\n",
    "ax[0,0].imshow(ref0, cmap='gray'); ax[0,0].set_title(\"Ref L0\")\n",
    "ax[0,1].imshow(rtl0, cmap='gray'); ax[0,1].set_title(\"RTL L0\")\n",
    "ax[0,2].imshow(np.abs(ref0-rtl0), cmap='hot'); ax[0,2].set_title(f\"Diff L0 ({err0:.4f})\")\n",
    "\n",
    "# L1\n",
    "ax[1,0].imshow(ref1, cmap='gray'); ax[1,0].set_title(\"Ref L1\")\n",
    "ax[1,1].imshow(rtl1, cmap='gray'); ax[1,1].set_title(\"RTL L1\")\n",
    "ax[1,2].imshow(np.abs(ref1-rtl1), cmap='hot'); ax[1,2].set_title(f\"Diff L1 ({err1:.4f})\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
